{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab ipynb - Colorization\n",
    "In diesem Notebook passiert das Training der Netzwerke.\n",
    "* Zuerst das Projekt von Github runterladen. Dafür werden Zugangsdaten benötigt, da das repo private ist im moment\n",
    "* google drive mounten um auf weights zuzugreifen\n",
    "* training loop ausfürhren\n",
    "\n",
    "Zusätlich kann man noch das den aktuellen repo stand von github ziehen mit `!git pull` ziehen und die GPU Informationen auslesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3183,
     "status": "ok",
     "timestamp": 1565862805873,
     "user": {
      "displayName": "Lukas Blecher",
      "photoUrl": "https://lh4.googleusercontent.com/-XtV6iVD9kww/AAAAAAAAAAI/AAAAAAAABoY/2RsKKwD6uh0/s64/photo.jpg",
      "userId": "14271751097560078622"
     },
     "user_tz": -120
    },
    "id": "2VbpZl_V4Zvv",
    "outputId": "9f583749-78bb-4300-e1d3-5bfef843ee90"
   },
   "outputs": [],
   "source": [
    "#für USERNAME und PASSWORD musst du deine GitHub-Zugangsdaten in plain text einsetzen.\n",
    "!git clone https://USERNAME:PASSWORD@github.com/ml4cdeca/AML_Colorization.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26922,
     "status": "ok",
     "timestamp": 1565862846454,
     "user": {
      "displayName": "Lukas Blecher",
      "photoUrl": "https://lh4.googleusercontent.com/-XtV6iVD9kww/AAAAAAAAAAI/AAAAAAAABoY/2RsKKwD6uh0/s64/photo.jpg",
      "userId": "14271751097560078622"
     },
     "user_tz": -120
    },
    "id": "c1tm3FZvSNb_",
    "outputId": "65679a77-2859-41ba-cc72-1565e7429e88"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#hier wird die google drive eingehängt wo wir die weights speichern (und evtl auch datensätze)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhXOYBY75XS2"
   },
   "outputs": [],
   "source": [
    "os.chdir('AML_Colorization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1053120,
     "status": "ok",
     "timestamp": 1565865856181,
     "user": {
      "displayName": "Lukas Blecher",
      "photoUrl": "https://lh4.googleusercontent.com/-XtV6iVD9kww/AAAAAAAAAAI/AAAAAAAABoY/2RsKKwD6uh0/s64/photo.jpg",
      "userId": "14271751097560078622"
     },
     "user_tz": -120
    },
    "id": "Lvs2HdoW5iJ6",
    "outputId": "a0b8a700-81f2-47db-dfce-436e899f9d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opts [('-b', '128'), ('-m', 'u'), ('-n', 'unet_cifar'), ('-w', '/content/drive/My Drive/Uni/6. Semester/Advanced Machine Learning/project/weights'), ('-e', '50')]\n",
      "NETWORK PATH: /content/drive/My Drive/Uni/6. Semester/Advanced Machine Learning/project/weights/unet_cifar.pth\n",
      "Files already downloaded and verified\n",
      "NETWORK PATH: /content/drive/My Drive/Uni/6. Semester/Advanced Machine Learning/project/weights/unet_cifar.pth\n",
      "Loaded weights from /content/drive/My Drive/Uni/6. Semester/Advanced Machine Learning/project/weights/unet_cifar.pth\n",
      "Loaded weights for discriminator from /content/drive/My Drive/Uni/6. Semester/Advanced Machine Learning/project/weights/unet_cifar_crit.pth\n",
      "Epoch 1, batch 10: \tunet loss=3.73e+00, \tcritic loss=7.83e-01\n",
      "Epoch 1, batch 20: \tunet loss=3.69e+00, \tcritic loss=7.12e-01\n",
      "Epoch 1, batch 30: \tunet loss=3.46e+00, \tcritic loss=6.35e-01\n",
      "Epoch 1, batch 40: \tunet loss=3.55e+00, \tcritic loss=6.37e-01\n",
      "Epoch 1, batch 50: \tunet loss=3.66e+00, \tcritic loss=7.01e-01\n",
      "Epoch 1, batch 60: \tunet loss=3.58e+00, \tcritic loss=6.42e-01\n",
      "Epoch 1, batch 70: \tunet loss=3.59e+00, \tcritic loss=7.07e-01\n",
      "Epoch 1, batch 80: \tunet loss=3.57e+00, \tcritic loss=7.32e-01\n",
      "Epoch 1, batch 90: \tunet loss=3.54e+00, \tcritic loss=7.53e-01\n",
      "Epoch 1, batch 100: \tunet loss=3.73e+00, \tcritic loss=7.96e-01\n",
      "Epoch 1, batch 110: \tunet loss=3.54e+00, \tcritic loss=6.56e-01\n",
      "Epoch 1, batch 120: \tunet loss=3.58e+00, \tcritic loss=7.61e-01\n",
      "Epoch 1, batch 130: \tunet loss=3.57e+00, \tcritic loss=7.41e-01\n",
      "Epoch 1, batch 140: \tunet loss=3.66e+00, \tcritic loss=6.67e-01\n",
      "Epoch 1, batch 150: \tunet loss=3.63e+00, \tcritic loss=6.29e-01\n",
      "Epoch 1, batch 160: \tunet loss=3.80e+00, \tcritic loss=5.89e-01\n",
      "Epoch 1, batch 170: \tunet loss=3.90e+00, \tcritic loss=5.64e-01\n",
      "Epoch 1, batch 180: \tunet loss=3.72e+00, \tcritic loss=6.57e-01\n",
      "Epoch 1, batch 190: \tunet loss=3.72e+00, \tcritic loss=6.98e-01\n",
      "Epoch 1, batch 200: \tunet loss=3.70e+00, \tcritic loss=6.74e-01\n",
      "Epoch 1, batch 210: \tunet loss=3.81e+00, \tcritic loss=6.10e-01\n",
      "Epoch 1, batch 220: \tunet loss=3.82e+00, \tcritic loss=6.41e-01\n",
      "Epoch 1, batch 230: \tunet loss=3.77e+00, \tcritic loss=6.54e-01\n",
      "Epoch 1, batch 240: \tunet loss=3.66e+00, \tcritic loss=6.40e-01\n",
      "Epoch 1, batch 250: \tunet loss=3.63e+00, \tcritic loss=6.94e-01\n",
      "Epoch 1, batch 260: \tunet loss=3.41e+00, \tcritic loss=6.42e-01\n",
      "Epoch 1, batch 270: \tunet loss=3.69e+00, \tcritic loss=6.91e-01\n",
      "Epoch 1, batch 280: \tunet loss=3.71e+00, \tcritic loss=6.88e-01\n",
      "Epoch 1, batch 290: \tunet loss=3.75e+00, \tcritic loss=6.11e-01\n",
      "Epoch 1, batch 300: \tunet loss=3.83e+00, \tcritic loss=7.28e-01\n",
      "Epoch 1, batch 310: \tunet loss=3.80e+00, \tcritic loss=7.78e-01\n",
      "Epoch 1, batch 320: \tunet loss=3.66e+00, \tcritic loss=8.55e-01\n",
      "Epoch 1, batch 330: \tunet loss=3.62e+00, \tcritic loss=8.33e-01\n",
      "Epoch 1, batch 340: \tunet loss=3.66e+00, \tcritic loss=7.19e-01\n",
      "Epoch 1, batch 350: \tunet loss=3.61e+00, \tcritic loss=6.47e-01\n",
      "Epoch 1, batch 360: \tunet loss=3.47e+00, \tcritic loss=6.71e-01\n",
      "Epoch 1, batch 370: \tunet loss=3.54e+00, \tcritic loss=6.73e-01\n",
      "Epoch 1, batch 380: \tunet loss=3.46e+00, \tcritic loss=6.76e-01\n",
      "Epoch 1, batch 390: \tunet loss=3.45e+00, \tcritic loss=6.60e-01\n",
      "Epoch 2, batch 9: \tunet loss=3.19e+00, \tcritic loss=6.08e-01\n",
      "Epoch 2, batch 19: \tunet loss=3.58e+00, \tcritic loss=6.82e-01\n",
      "Epoch 2, batch 29: \tunet loss=3.51e+00, \tcritic loss=6.32e-01\n",
      "Epoch 2, batch 39: \tunet loss=3.62e+00, \tcritic loss=7.02e-01\n",
      "Epoch 2, batch 49: \tunet loss=3.66e+00, \tcritic loss=6.69e-01\n",
      "Epoch 2, batch 59: \tunet loss=3.55e+00, \tcritic loss=6.93e-01\n",
      "Epoch 2, batch 69: \tunet loss=3.60e+00, \tcritic loss=6.49e-01\n",
      "Epoch 2, batch 79: \tunet loss=3.67e+00, \tcritic loss=6.30e-01\n",
      "Epoch 2, batch 89: \tunet loss=3.60e+00, \tcritic loss=6.98e-01\n",
      "Epoch 2, batch 99: \tunet loss=3.62e+00, \tcritic loss=7.15e-01\n",
      "Epoch 2, batch 109: \tunet loss=3.52e+00, \tcritic loss=6.85e-01\n",
      "saved parameters\n",
      "Epoch 2, batch 119: \tunet loss=3.60e+00, \tcritic loss=6.94e-01\n",
      "Epoch 2, batch 129: \tunet loss=3.53e+00, \tcritic loss=6.66e-01\n",
      "Epoch 2, batch 139: \tunet loss=3.61e+00, \tcritic loss=7.06e-01\n",
      "Epoch 2, batch 149: \tunet loss=3.51e+00, \tcritic loss=6.78e-01\n",
      "Epoch 2, batch 159: \tunet loss=3.60e+00, \tcritic loss=6.83e-01\n",
      "Epoch 2, batch 169: \tunet loss=3.50e+00, \tcritic loss=6.79e-01\n",
      "Epoch 2, batch 179: \tunet loss=3.57e+00, \tcritic loss=6.94e-01\n",
      "Epoch 2, batch 189: \tunet loss=3.60e+00, \tcritic loss=6.58e-01\n",
      "Epoch 2, batch 199: \tunet loss=3.61e+00, \tcritic loss=6.37e-01\n",
      "Epoch 2, batch 209: \tunet loss=3.59e+00, \tcritic loss=6.52e-01\n",
      "Epoch 2, batch 219: \tunet loss=3.59e+00, \tcritic loss=6.40e-01\n",
      "Epoch 2, batch 229: \tunet loss=3.71e+00, \tcritic loss=6.45e-01\n",
      "Epoch 2, batch 239: \tunet loss=3.83e+00, \tcritic loss=7.02e-01\n",
      "Epoch 2, batch 249: \tunet loss=3.58e+00, \tcritic loss=6.88e-01\n",
      "Epoch 2, batch 259: \tunet loss=3.73e+00, \tcritic loss=7.48e-01\n",
      "Epoch 2, batch 269: \tunet loss=3.76e+00, \tcritic loss=6.30e-01\n",
      "Epoch 2, batch 279: \tunet loss=3.77e+00, \tcritic loss=6.04e-01\n",
      "Epoch 2, batch 289: \tunet loss=3.74e+00, \tcritic loss=7.70e-01\n",
      "Epoch 2, batch 299: \tunet loss=3.85e+00, \tcritic loss=7.55e-01\n",
      "Epoch 2, batch 309: \tunet loss=3.87e+00, \tcritic loss=7.03e-01\n",
      "Epoch 2, batch 319: \tunet loss=3.72e+00, \tcritic loss=6.82e-01\n",
      "Epoch 2, batch 329: \tunet loss=3.59e+00, \tcritic loss=6.86e-01\n",
      "Epoch 2, batch 339: \tunet loss=3.71e+00, \tcritic loss=6.70e-01\n",
      "Epoch 2, batch 349: \tunet loss=3.61e+00, \tcritic loss=7.26e-01\n",
      "Epoch 2, batch 359: \tunet loss=3.55e+00, \tcritic loss=6.71e-01\n",
      "Epoch 2, batch 369: \tunet loss=3.50e+00, \tcritic loss=6.95e-01\n",
      "Epoch 2, batch 379: \tunet loss=3.63e+00, \tcritic loss=6.98e-01\n",
      "Epoch 2, batch 389: \tunet loss=3.65e+00, \tcritic loss=7.02e-01\n",
      "Epoch 3, batch 8: \tunet loss=2.88e+00, \tcritic loss=5.21e-01\n",
      "Epoch 3, batch 18: \tunet loss=3.60e+00, \tcritic loss=6.16e-01\n",
      "Epoch 3, batch 28: \tunet loss=3.58e+00, \tcritic loss=6.71e-01\n",
      "Epoch 3, batch 38: \tunet loss=3.77e+00, \tcritic loss=6.70e-01\n",
      "Epoch 3, batch 48: \tunet loss=3.69e+00, \tcritic loss=7.19e-01\n",
      "Epoch 3, batch 58: \tunet loss=3.54e+00, \tcritic loss=6.78e-01\n",
      "Epoch 3, batch 68: \tunet loss=3.55e+00, \tcritic loss=6.66e-01\n",
      "Epoch 3, batch 78: \tunet loss=3.76e+00, \tcritic loss=6.81e-01\n",
      "Epoch 3, batch 88: \tunet loss=3.31e+00, \tcritic loss=7.19e-01\n",
      "Epoch 3, batch 98: \tunet loss=3.53e+00, \tcritic loss=7.59e-01\n",
      "Epoch 3, batch 108: \tunet loss=3.43e+00, \tcritic loss=6.76e-01\n",
      "Epoch 3, batch 118: \tunet loss=3.50e+00, \tcritic loss=6.59e-01\n",
      "Epoch 3, batch 128: \tunet loss=3.54e+00, \tcritic loss=7.02e-01\n",
      "Epoch 3, batch 138: \tunet loss=3.50e+00, \tcritic loss=6.68e-01\n",
      "Epoch 3, batch 148: \tunet loss=3.57e+00, \tcritic loss=6.65e-01\n",
      "Epoch 3, batch 158: \tunet loss=3.45e+00, \tcritic loss=7.08e-01\n",
      "Epoch 3, batch 168: \tunet loss=3.51e+00, \tcritic loss=7.20e-01\n",
      "Epoch 3, batch 178: \tunet loss=3.57e+00, \tcritic loss=6.31e-01\n",
      "Epoch 3, batch 188: \tunet loss=3.59e+00, \tcritic loss=6.70e-01\n",
      "Epoch 3, batch 198: \tunet loss=3.57e+00, \tcritic loss=6.44e-01\n",
      "Epoch 3, batch 208: \tunet loss=3.54e+00, \tcritic loss=6.51e-01\n",
      "Epoch 3, batch 218: \tunet loss=3.55e+00, \tcritic loss=6.94e-01\n",
      "saved parameters\n",
      "Epoch 3, batch 228: \tunet loss=3.71e+00, \tcritic loss=6.50e-01\n",
      "Epoch 3, batch 238: \tunet loss=3.67e+00, \tcritic loss=6.68e-01\n",
      "Epoch 3, batch 248: \tunet loss=3.66e+00, \tcritic loss=6.44e-01\n",
      "Epoch 3, batch 258: \tunet loss=3.64e+00, \tcritic loss=7.09e-01\n",
      "Epoch 3, batch 268: \tunet loss=3.46e+00, \tcritic loss=6.71e-01\n",
      "Epoch 3, batch 278: \tunet loss=3.59e+00, \tcritic loss=6.73e-01\n",
      "Epoch 3, batch 288: \tunet loss=3.56e+00, \tcritic loss=7.33e-01\n",
      "Epoch 3, batch 298: \tunet loss=3.56e+00, \tcritic loss=7.76e-01\n",
      "Epoch 3, batch 308: \tunet loss=3.69e+00, \tcritic loss=6.96e-01\n",
      "Epoch 3, batch 318: \tunet loss=3.54e+00, \tcritic loss=6.64e-01\n",
      "Epoch 3, batch 328: \tunet loss=3.70e+00, \tcritic loss=7.00e-01\n",
      "Epoch 3, batch 338: \tunet loss=3.53e+00, \tcritic loss=7.30e-01\n",
      "Epoch 3, batch 348: \tunet loss=3.43e+00, \tcritic loss=6.85e-01\n",
      "Epoch 3, batch 358: \tunet loss=3.56e+00, \tcritic loss=6.60e-01\n",
      "Epoch 3, batch 368: \tunet loss=3.35e+00, \tcritic loss=6.89e-01\n",
      "Epoch 3, batch 378: \tunet loss=3.51e+00, \tcritic loss=6.51e-01\n",
      "Epoch 3, batch 388: \tunet loss=3.66e+00, \tcritic loss=6.86e-01\n",
      "Epoch 4, batch 7: \tunet loss=2.64e+00, \tcritic loss=4.36e-01\n",
      "Epoch 4, batch 17: \tunet loss=3.56e+00, \tcritic loss=6.38e-01\n",
      "Epoch 4, batch 27: \tunet loss=3.71e+00, \tcritic loss=6.79e-01\n",
      "Epoch 4, batch 37: \tunet loss=3.63e+00, \tcritic loss=6.08e-01\n",
      "Epoch 4, batch 47: \tunet loss=3.97e+00, \tcritic loss=6.20e-01\n",
      "Epoch 4, batch 57: \tunet loss=3.67e+00, \tcritic loss=5.90e-01\n",
      "Epoch 4, batch 67: \tunet loss=3.76e+00, \tcritic loss=7.34e-01\n",
      "Epoch 4, batch 77: \tunet loss=3.71e+00, \tcritic loss=6.79e-01\n",
      "Epoch 4, batch 87: \tunet loss=3.71e+00, \tcritic loss=7.03e-01\n",
      "Epoch 4, batch 97: \tunet loss=3.66e+00, \tcritic loss=7.25e-01\n",
      "Epoch 4, batch 107: \tunet loss=3.59e+00, \tcritic loss=7.12e-01\n",
      "Epoch 4, batch 117: \tunet loss=3.58e+00, \tcritic loss=7.22e-01\n",
      "Epoch 4, batch 127: \tunet loss=3.42e+00, \tcritic loss=6.33e-01\n",
      "Epoch 4, batch 137: \tunet loss=3.63e+00, \tcritic loss=6.12e-01\n",
      "Epoch 4, batch 147: \tunet loss=3.64e+00, \tcritic loss=5.49e-01\n",
      "Epoch 4, batch 157: \tunet loss=3.78e+00, \tcritic loss=6.35e-01\n",
      "Epoch 4, batch 167: \tunet loss=3.74e+00, \tcritic loss=6.84e-01\n",
      "Epoch 4, batch 177: \tunet loss=3.61e+00, \tcritic loss=8.21e-01\n",
      "Epoch 4, batch 187: \tunet loss=3.49e+00, \tcritic loss=7.38e-01\n",
      "Epoch 4, batch 197: \tunet loss=3.50e+00, \tcritic loss=6.77e-01\n",
      "Epoch 4, batch 207: \tunet loss=3.48e+00, \tcritic loss=6.48e-01\n",
      "Epoch 4, batch 217: \tunet loss=3.59e+00, \tcritic loss=6.07e-01\n",
      "Epoch 4, batch 227: \tunet loss=3.68e+00, \tcritic loss=6.20e-01\n",
      "Epoch 4, batch 237: \tunet loss=3.73e+00, \tcritic loss=6.93e-01\n",
      "Epoch 4, batch 247: \tunet loss=3.56e+00, \tcritic loss=7.66e-01\n",
      "Epoch 4, batch 257: \tunet loss=3.41e+00, \tcritic loss=7.35e-01\n",
      "Epoch 4, batch 267: \tunet loss=3.67e+00, \tcritic loss=6.29e-01\n",
      "Epoch 4, batch 277: \tunet loss=3.66e+00, \tcritic loss=6.63e-01\n",
      "Epoch 4, batch 287: \tunet loss=3.52e+00, \tcritic loss=6.85e-01\n",
      "Epoch 4, batch 297: \tunet loss=3.55e+00, \tcritic loss=7.41e-01\n",
      "Epoch 4, batch 307: \tunet loss=3.57e+00, \tcritic loss=6.95e-01\n",
      "Epoch 4, batch 317: \tunet loss=3.58e+00, \tcritic loss=7.87e-01\n",
      "Epoch 4, batch 327: \tunet loss=3.46e+00, \tcritic loss=7.48e-01\n",
      "saved parameters\n",
      "Epoch 4, batch 337: \tunet loss=3.65e+00, \tcritic loss=6.60e-01\n",
      "Epoch 4, batch 347: \tunet loss=3.47e+00, \tcritic loss=6.69e-01\n",
      "Epoch 4, batch 357: \tunet loss=3.39e+00, \tcritic loss=6.97e-01\n",
      "Epoch 4, batch 367: \tunet loss=3.72e+00, \tcritic loss=6.43e-01\n",
      "Epoch 4, batch 377: \tunet loss=3.80e+00, \tcritic loss=5.82e-01\n",
      "Epoch 4, batch 387: \tunet loss=3.85e+00, \tcritic loss=5.89e-01\n",
      "Epoch 5, batch 6: \tunet loss=2.33e+00, \tcritic loss=3.64e-01\n",
      "Epoch 5, batch 16: \tunet loss=3.84e+00, \tcritic loss=6.79e-01\n",
      "Epoch 5, batch 26: \tunet loss=4.02e+00, \tcritic loss=7.12e-01\n",
      "Epoch 5, batch 36: \tunet loss=3.81e+00, \tcritic loss=6.60e-01\n",
      "Epoch 5, batch 46: \tunet loss=4.08e+00, \tcritic loss=6.68e-01\n",
      "Epoch 5, batch 56: \tunet loss=3.79e+00, \tcritic loss=7.37e-01\n",
      "Epoch 5, batch 66: \tunet loss=3.67e+00, \tcritic loss=6.74e-01\n",
      "Epoch 5, batch 76: \tunet loss=3.65e+00, \tcritic loss=6.36e-01\n",
      "Epoch 5, batch 86: \tunet loss=3.72e+00, \tcritic loss=6.34e-01\n",
      "Epoch 5, batch 96: \tunet loss=3.65e+00, \tcritic loss=6.43e-01\n",
      "Epoch 5, batch 106: \tunet loss=3.52e+00, \tcritic loss=6.70e-01\n",
      "Epoch 5, batch 116: \tunet loss=3.66e+00, \tcritic loss=6.18e-01\n",
      "Epoch 5, batch 126: \tunet loss=3.56e+00, \tcritic loss=6.10e-01\n",
      "Epoch 5, batch 136: \tunet loss=3.47e+00, \tcritic loss=7.01e-01\n",
      "Epoch 5, batch 146: \tunet loss=3.72e+00, \tcritic loss=7.22e-01\n",
      "Epoch 5, batch 156: \tunet loss=3.77e+00, \tcritic loss=7.08e-01\n",
      "Epoch 5, batch 166: \tunet loss=3.75e+00, \tcritic loss=6.61e-01\n",
      "Epoch 5, batch 176: \tunet loss=3.61e+00, \tcritic loss=6.59e-01\n",
      "Epoch 5, batch 186: \tunet loss=3.65e+00, \tcritic loss=7.00e-01\n",
      "Epoch 5, batch 196: \tunet loss=3.64e+00, \tcritic loss=6.87e-01\n",
      "Epoch 5, batch 206: \tunet loss=3.63e+00, \tcritic loss=6.65e-01\n",
      "Epoch 5, batch 216: \tunet loss=3.71e+00, \tcritic loss=7.34e-01\n",
      "Epoch 5, batch 226: \tunet loss=3.47e+00, \tcritic loss=7.02e-01\n",
      "Epoch 5, batch 236: \tunet loss=3.75e+00, \tcritic loss=7.41e-01\n",
      "Epoch 5, batch 246: \tunet loss=3.49e+00, \tcritic loss=6.92e-01\n",
      "Epoch 5, batch 256: \tunet loss=3.58e+00, \tcritic loss=7.05e-01\n",
      "Epoch 5, batch 266: \tunet loss=3.55e+00, \tcritic loss=6.64e-01\n",
      "Epoch 5, batch 276: \tunet loss=3.61e+00, \tcritic loss=6.40e-01\n",
      "Epoch 5, batch 286: \tunet loss=3.67e+00, \tcritic loss=6.78e-01\n",
      "Epoch 5, batch 296: \tunet loss=3.58e+00, \tcritic loss=6.31e-01\n",
      "Epoch 5, batch 306: \tunet loss=3.66e+00, \tcritic loss=7.14e-01\n",
      "Epoch 5, batch 316: \tunet loss=3.58e+00, \tcritic loss=7.42e-01\n",
      "Epoch 5, batch 326: \tunet loss=3.70e+00, \tcritic loss=7.42e-01\n",
      "Epoch 5, batch 336: \tunet loss=3.55e+00, \tcritic loss=6.65e-01\n",
      "Epoch 5, batch 346: \tunet loss=3.59e+00, \tcritic loss=6.33e-01\n",
      "Epoch 5, batch 356: \tunet loss=3.68e+00, \tcritic loss=7.12e-01\n",
      "Epoch 5, batch 366: \tunet loss=3.53e+00, \tcritic loss=6.32e-01\n",
      "Epoch 5, batch 376: \tunet loss=3.72e+00, \tcritic loss=6.39e-01\n",
      "Epoch 5, batch 386: \tunet loss=3.64e+00, \tcritic loss=6.52e-01\n",
      "Epoch 6, batch 5: \tunet loss=1.88e+00, \tcritic loss=3.38e-01\n",
      "Epoch 6, batch 15: \tunet loss=3.79e+00, \tcritic loss=6.55e-01\n",
      "Epoch 6, batch 25: \tunet loss=3.78e+00, \tcritic loss=6.70e-01\n",
      "Epoch 6, batch 35: \tunet loss=3.82e+00, \tcritic loss=6.81e-01\n",
      "Epoch 6, batch 45: \tunet loss=3.80e+00, \tcritic loss=6.15e-01\n",
      "saved parameters\n",
      "Epoch 6, batch 55: \tunet loss=3.69e+00, \tcritic loss=7.04e-01\n",
      "Epoch 6, batch 65: \tunet loss=3.47e+00, \tcritic loss=7.45e-01\n",
      "Epoch 6, batch 75: \tunet loss=3.61e+00, \tcritic loss=6.72e-01\n",
      "Epoch 6, batch 85: \tunet loss=3.65e+00, \tcritic loss=6.33e-01\n",
      "Epoch 6, batch 95: \tunet loss=3.73e+00, \tcritic loss=6.66e-01\n",
      "Epoch 6, batch 105: \tunet loss=3.66e+00, \tcritic loss=6.84e-01\n",
      "Epoch 6, batch 115: \tunet loss=3.68e+00, \tcritic loss=6.94e-01\n",
      "Epoch 6, batch 125: \tunet loss=3.76e+00, \tcritic loss=6.89e-01\n",
      "Epoch 6, batch 135: \tunet loss=3.84e+00, \tcritic loss=6.87e-01\n",
      "Epoch 6, batch 145: \tunet loss=3.83e+00, \tcritic loss=6.27e-01\n",
      "Epoch 6, batch 155: \tunet loss=3.73e+00, \tcritic loss=6.86e-01\n",
      "Epoch 6, batch 165: \tunet loss=3.59e+00, \tcritic loss=6.67e-01\n",
      "Epoch 6, batch 175: \tunet loss=3.57e+00, \tcritic loss=6.59e-01\n",
      "Epoch 6, batch 185: \tunet loss=3.69e+00, \tcritic loss=6.48e-01\n",
      "Epoch 6, batch 195: \tunet loss=3.56e+00, \tcritic loss=6.85e-01\n",
      "Epoch 6, batch 205: \tunet loss=3.68e+00, \tcritic loss=6.85e-01\n",
      "Epoch 6, batch 215: \tunet loss=3.73e+00, \tcritic loss=6.20e-01\n",
      "Epoch 6, batch 225: \tunet loss=3.63e+00, \tcritic loss=7.03e-01\n",
      "Epoch 6, batch 235: \tunet loss=3.69e+00, \tcritic loss=6.59e-01\n",
      "Epoch 6, batch 245: \tunet loss=3.64e+00, \tcritic loss=6.94e-01\n",
      "Epoch 6, batch 255: \tunet loss=3.57e+00, \tcritic loss=6.78e-01\n",
      "Epoch 6, batch 265: \tunet loss=3.64e+00, \tcritic loss=7.04e-01\n",
      "Epoch 6, batch 275: \tunet loss=3.71e+00, \tcritic loss=6.86e-01\n",
      "Epoch 6, batch 285: \tunet loss=3.71e+00, \tcritic loss=7.38e-01\n",
      "Epoch 6, batch 295: \tunet loss=3.65e+00, \tcritic loss=7.06e-01\n",
      "Epoch 6, batch 305: \tunet loss=3.64e+00, \tcritic loss=7.07e-01\n",
      "Epoch 6, batch 315: \tunet loss=3.58e+00, \tcritic loss=6.79e-01\n",
      "Epoch 6, batch 325: \tunet loss=3.70e+00, \tcritic loss=7.45e-01\n",
      "Epoch 6, batch 335: \tunet loss=3.64e+00, \tcritic loss=6.50e-01\n",
      "Epoch 6, batch 345: \tunet loss=3.48e+00, \tcritic loss=6.46e-01\n",
      "Epoch 6, batch 355: \tunet loss=3.55e+00, \tcritic loss=6.47e-01\n",
      "Epoch 6, batch 365: \tunet loss=3.69e+00, \tcritic loss=6.67e-01\n",
      "Epoch 6, batch 375: \tunet loss=3.72e+00, \tcritic loss=6.46e-01\n",
      "Epoch 6, batch 385: \tunet loss=3.67e+00, \tcritic loss=6.45e-01\n",
      "Epoch 7, batch 4: \tunet loss=1.46e+00, \tcritic loss=3.21e-01\n",
      "Epoch 7, batch 14: \tunet loss=3.59e+00, \tcritic loss=8.06e-01\n",
      "Epoch 7, batch 24: \tunet loss=3.56e+00, \tcritic loss=7.49e-01\n",
      "Epoch 7, batch 34: \tunet loss=3.61e+00, \tcritic loss=6.12e-01\n",
      "Epoch 7, batch 44: \tunet loss=3.79e+00, \tcritic loss=5.78e-01\n",
      "Epoch 7, batch 54: \tunet loss=3.49e+00, \tcritic loss=5.88e-01\n",
      "Epoch 7, batch 64: \tunet loss=3.58e+00, \tcritic loss=7.00e-01\n",
      "Epoch 7, batch 74: \tunet loss=3.57e+00, \tcritic loss=7.29e-01\n",
      "Epoch 7, batch 84: \tunet loss=3.75e+00, \tcritic loss=7.17e-01\n",
      "Epoch 7, batch 94: \tunet loss=3.81e+00, \tcritic loss=7.51e-01\n",
      "Epoch 7, batch 104: \tunet loss=3.64e+00, \tcritic loss=7.27e-01\n",
      "Epoch 7, batch 114: \tunet loss=3.70e+00, \tcritic loss=7.92e-01\n",
      "Epoch 7, batch 124: \tunet loss=3.58e+00, \tcritic loss=6.92e-01\n",
      "Epoch 7, batch 134: \tunet loss=3.63e+00, \tcritic loss=6.91e-01\n",
      "Epoch 7, batch 144: \tunet loss=3.55e+00, \tcritic loss=6.71e-01\n",
      "Epoch 7, batch 154: \tunet loss=3.49e+00, \tcritic loss=7.01e-01\n",
      "saved parameters\n",
      "Epoch 7, batch 164: \tunet loss=3.57e+00, \tcritic loss=6.85e-01\n",
      "Epoch 7, batch 174: \tunet loss=3.64e+00, \tcritic loss=6.66e-01\n",
      "Epoch 7, batch 184: \tunet loss=3.51e+00, \tcritic loss=7.05e-01\n",
      "Epoch 7, batch 194: \tunet loss=3.57e+00, \tcritic loss=6.66e-01\n",
      "Epoch 7, batch 204: \tunet loss=3.64e+00, \tcritic loss=6.65e-01\n",
      "Epoch 7, batch 214: \tunet loss=3.57e+00, \tcritic loss=6.22e-01\n",
      "Epoch 7, batch 224: \tunet loss=3.69e+00, \tcritic loss=6.16e-01\n",
      "Epoch 7, batch 234: \tunet loss=3.64e+00, \tcritic loss=7.91e-01\n",
      "Epoch 7, batch 244: \tunet loss=3.65e+00, \tcritic loss=6.70e-01\n",
      "Epoch 7, batch 254: \tunet loss=3.57e+00, \tcritic loss=7.84e-01\n",
      "Epoch 7, batch 264: \tunet loss=3.58e+00, \tcritic loss=7.64e-01\n",
      "Epoch 7, batch 274: \tunet loss=3.73e+00, \tcritic loss=6.77e-01\n",
      "Epoch 7, batch 284: \tunet loss=3.52e+00, \tcritic loss=5.91e-01\n",
      "Epoch 7, batch 294: \tunet loss=3.57e+00, \tcritic loss=5.86e-01\n",
      "Epoch 7, batch 304: \tunet loss=3.53e+00, \tcritic loss=6.70e-01\n",
      "Epoch 7, batch 314: \tunet loss=3.46e+00, \tcritic loss=7.13e-01\n",
      "Epoch 7, batch 324: \tunet loss=3.48e+00, \tcritic loss=6.60e-01\n",
      "Epoch 7, batch 334: \tunet loss=3.54e+00, \tcritic loss=6.82e-01\n",
      "Epoch 7, batch 344: \tunet loss=3.52e+00, \tcritic loss=6.56e-01\n",
      "Epoch 7, batch 354: \tunet loss=3.55e+00, \tcritic loss=6.79e-01\n",
      "Epoch 7, batch 364: \tunet loss=3.57e+00, \tcritic loss=6.58e-01\n",
      "Epoch 7, batch 374: \tunet loss=3.46e+00, \tcritic loss=6.70e-01\n",
      "Epoch 7, batch 384: \tunet loss=3.60e+00, \tcritic loss=6.91e-01\n",
      "Epoch 8, batch 3: \tunet loss=1.08e+00, \tcritic loss=2.14e-01\n",
      "Epoch 8, batch 13: \tunet loss=3.62e+00, \tcritic loss=6.98e-01\n",
      "Epoch 8, batch 23: \tunet loss=3.68e+00, \tcritic loss=7.32e-01\n",
      "Epoch 8, batch 33: \tunet loss=3.43e+00, \tcritic loss=6.21e-01\n",
      "Epoch 8, batch 43: \tunet loss=3.69e+00, \tcritic loss=6.35e-01\n",
      "Epoch 8, batch 53: \tunet loss=3.60e+00, \tcritic loss=7.44e-01\n",
      "Epoch 8, batch 63: \tunet loss=3.70e+00, \tcritic loss=6.87e-01\n",
      "Epoch 8, batch 73: \tunet loss=3.61e+00, \tcritic loss=6.58e-01\n",
      "Epoch 8, batch 83: \tunet loss=3.52e+00, \tcritic loss=6.81e-01\n",
      "Epoch 8, batch 93: \tunet loss=3.63e+00, \tcritic loss=7.26e-01\n",
      "Epoch 8, batch 103: \tunet loss=3.49e+00, \tcritic loss=7.31e-01\n",
      "Epoch 8, batch 113: \tunet loss=3.60e+00, \tcritic loss=6.98e-01\n",
      "Epoch 8, batch 123: \tunet loss=3.51e+00, \tcritic loss=6.26e-01\n",
      "Epoch 8, batch 133: \tunet loss=3.63e+00, \tcritic loss=7.13e-01\n",
      "Epoch 8, batch 143: \tunet loss=3.60e+00, \tcritic loss=6.82e-01\n",
      "Epoch 8, batch 153: \tunet loss=3.49e+00, \tcritic loss=6.85e-01\n",
      "Epoch 8, batch 163: \tunet loss=3.61e+00, \tcritic loss=6.78e-01\n",
      "Epoch 8, batch 173: \tunet loss=3.63e+00, \tcritic loss=7.14e-01\n",
      "Epoch 8, batch 183: \tunet loss=3.53e+00, \tcritic loss=6.53e-01\n",
      "Epoch 8, batch 193: \tunet loss=3.61e+00, \tcritic loss=5.72e-01\n",
      "Epoch 8, batch 203: \tunet loss=3.58e+00, \tcritic loss=6.23e-01\n",
      "Epoch 8, batch 213: \tunet loss=3.82e+00, \tcritic loss=6.86e-01\n",
      "Epoch 8, batch 223: \tunet loss=3.80e+00, \tcritic loss=6.76e-01\n",
      "Epoch 8, batch 233: \tunet loss=3.66e+00, \tcritic loss=7.60e-01\n",
      "Epoch 8, batch 243: \tunet loss=3.54e+00, \tcritic loss=7.36e-01\n",
      "Epoch 8, batch 253: \tunet loss=3.57e+00, \tcritic loss=6.69e-01\n",
      "Epoch 8, batch 263: \tunet loss=3.70e+00, \tcritic loss=7.23e-01\n",
      "saved parameters\n",
      "Epoch 8, batch 273: \tunet loss=3.56e+00, \tcritic loss=6.50e-01\n",
      "Epoch 8, batch 283: \tunet loss=3.47e+00, \tcritic loss=6.64e-01\n",
      "Epoch 8, batch 293: \tunet loss=3.51e+00, \tcritic loss=6.61e-01\n",
      "Epoch 8, batch 303: \tunet loss=3.52e+00, \tcritic loss=7.25e-01\n",
      "Epoch 8, batch 313: \tunet loss=3.89e+00, \tcritic loss=7.00e-01\n",
      "Epoch 8, batch 323: \tunet loss=3.58e+00, \tcritic loss=7.07e-01\n",
      "Epoch 8, batch 333: \tunet loss=3.62e+00, \tcritic loss=6.95e-01\n",
      "Epoch 8, batch 343: \tunet loss=3.57e+00, \tcritic loss=6.97e-01\n",
      "Epoch 8, batch 353: \tunet loss=3.50e+00, \tcritic loss=6.46e-01\n",
      "Epoch 8, batch 363: \tunet loss=3.58e+00, \tcritic loss=6.23e-01\n",
      "Epoch 8, batch 373: \tunet loss=3.50e+00, \tcritic loss=7.84e-01\n",
      "Epoch 8, batch 383: \tunet loss=3.46e+00, \tcritic loss=7.88e-01\n",
      "Epoch 9, batch 2: \tunet loss=7.50e-01, \tcritic loss=1.29e-01\n",
      "Epoch 9, batch 12: \tunet loss=3.67e+00, \tcritic loss=6.69e-01\n",
      "Epoch 9, batch 22: \tunet loss=3.61e+00, \tcritic loss=6.85e-01\n",
      "Epoch 9, batch 32: \tunet loss=3.52e+00, \tcritic loss=7.11e-01\n",
      "Epoch 9, batch 42: \tunet loss=3.58e+00, \tcritic loss=7.11e-01\n",
      "Epoch 9, batch 52: \tunet loss=3.66e+00, \tcritic loss=6.60e-01\n",
      "Epoch 9, batch 62: \tunet loss=3.58e+00, \tcritic loss=6.86e-01\n",
      "Epoch 9, batch 72: \tunet loss=3.45e+00, \tcritic loss=7.12e-01\n",
      "Epoch 9, batch 82: \tunet loss=3.59e+00, \tcritic loss=6.95e-01\n",
      "Epoch 9, batch 92: \tunet loss=3.48e+00, \tcritic loss=6.54e-01\n",
      "Epoch 9, batch 102: \tunet loss=3.62e+00, \tcritic loss=6.84e-01\n",
      "Epoch 9, batch 112: \tunet loss=3.57e+00, \tcritic loss=6.56e-01\n",
      "Epoch 9, batch 122: \tunet loss=3.57e+00, \tcritic loss=6.89e-01\n",
      "Epoch 9, batch 132: \tunet loss=3.46e+00, \tcritic loss=6.50e-01\n",
      "Epoch 9, batch 142: \tunet loss=3.66e+00, \tcritic loss=6.75e-01\n",
      "Epoch 9, batch 152: \tunet loss=3.65e+00, \tcritic loss=7.19e-01\n",
      "Epoch 9, batch 162: \tunet loss=3.69e+00, \tcritic loss=7.49e-01\n",
      "Epoch 9, batch 172: \tunet loss=3.51e+00, \tcritic loss=7.32e-01\n",
      "Epoch 9, batch 182: \tunet loss=3.58e+00, \tcritic loss=6.88e-01\n",
      "Epoch 9, batch 192: \tunet loss=3.65e+00, \tcritic loss=6.26e-01\n",
      "Epoch 9, batch 202: \tunet loss=3.60e+00, \tcritic loss=6.26e-01\n",
      "Epoch 9, batch 212: \tunet loss=3.55e+00, \tcritic loss=7.07e-01\n",
      "Epoch 9, batch 222: \tunet loss=3.43e+00, \tcritic loss=7.12e-01\n",
      "Epoch 9, batch 232: \tunet loss=3.48e+00, \tcritic loss=7.27e-01\n",
      "Epoch 9, batch 242: \tunet loss=3.50e+00, \tcritic loss=6.60e-01\n",
      "Epoch 9, batch 252: \tunet loss=3.54e+00, \tcritic loss=6.51e-01\n",
      "Epoch 9, batch 262: \tunet loss=3.63e+00, \tcritic loss=6.59e-01\n",
      "Epoch 9, batch 272: \tunet loss=3.65e+00, \tcritic loss=7.06e-01\n",
      "Epoch 9, batch 282: \tunet loss=3.55e+00, \tcritic loss=6.87e-01\n",
      "Epoch 9, batch 292: \tunet loss=3.47e+00, \tcritic loss=6.97e-01\n",
      "Epoch 9, batch 302: \tunet loss=3.55e+00, \tcritic loss=6.63e-01\n",
      "Epoch 9, batch 312: \tunet loss=3.47e+00, \tcritic loss=6.81e-01\n",
      "Epoch 9, batch 322: \tunet loss=3.39e+00, \tcritic loss=6.61e-01\n",
      "Epoch 9, batch 332: \tunet loss=3.48e+00, \tcritic loss=6.62e-01\n",
      "Epoch 9, batch 342: \tunet loss=3.58e+00, \tcritic loss=6.94e-01\n",
      "Epoch 9, batch 352: \tunet loss=3.51e+00, \tcritic loss=6.77e-01\n",
      "Epoch 9, batch 362: \tunet loss=3.54e+00, \tcritic loss=7.31e-01\n",
      "Epoch 9, batch 372: \tunet loss=3.55e+00, \tcritic loss=7.23e-01\n",
      "saved parameters\n",
      "Epoch 9, batch 382: \tunet loss=3.61e+00, \tcritic loss=6.02e-01\n",
      "Epoch 10, batch 1: \tunet loss=3.25e-01, \tcritic loss=7.37e-02\n",
      "Epoch 10, batch 11: \tunet loss=3.57e+00, \tcritic loss=7.63e-01\n",
      "Epoch 10, batch 21: \tunet loss=3.62e+00, \tcritic loss=7.10e-01\n",
      "Epoch 10, batch 31: \tunet loss=3.54e+00, \tcritic loss=7.08e-01\n",
      "Epoch 10, batch 41: \tunet loss=3.51e+00, \tcritic loss=7.69e-01\n",
      "Epoch 10, batch 51: \tunet loss=3.52e+00, \tcritic loss=7.37e-01\n",
      "Epoch 10, batch 61: \tunet loss=3.46e+00, \tcritic loss=7.02e-01\n",
      "Epoch 10, batch 71: \tunet loss=3.44e+00, \tcritic loss=6.71e-01\n",
      "Epoch 10, batch 81: \tunet loss=3.53e+00, \tcritic loss=6.62e-01\n",
      "Epoch 10, batch 91: \tunet loss=3.61e+00, \tcritic loss=6.81e-01\n",
      "Epoch 10, batch 101: \tunet loss=3.54e+00, \tcritic loss=7.01e-01\n",
      "Epoch 10, batch 111: \tunet loss=3.44e+00, \tcritic loss=6.82e-01\n",
      "Epoch 10, batch 121: \tunet loss=3.53e+00, \tcritic loss=6.35e-01\n",
      "Epoch 10, batch 131: \tunet loss=3.58e+00, \tcritic loss=6.75e-01\n",
      "Epoch 10, batch 141: \tunet loss=3.38e+00, \tcritic loss=6.39e-01\n",
      "Epoch 10, batch 151: \tunet loss=3.57e+00, \tcritic loss=6.97e-01\n",
      "Epoch 10, batch 161: \tunet loss=3.51e+00, \tcritic loss=6.23e-01\n",
      "Epoch 10, batch 171: \tunet loss=3.51e+00, \tcritic loss=7.24e-01\n",
      "Epoch 10, batch 181: \tunet loss=3.34e+00, \tcritic loss=6.95e-01\n",
      "Epoch 10, batch 191: \tunet loss=3.55e+00, \tcritic loss=7.40e-01\n",
      "Epoch 10, batch 201: \tunet loss=3.49e+00, \tcritic loss=6.97e-01\n",
      "Epoch 10, batch 211: \tunet loss=3.55e+00, \tcritic loss=7.05e-01\n",
      "Epoch 10, batch 221: \tunet loss=3.60e+00, \tcritic loss=7.37e-01\n",
      "Epoch 10, batch 231: \tunet loss=3.59e+00, \tcritic loss=6.77e-01\n",
      "Epoch 10, batch 241: \tunet loss=3.49e+00, \tcritic loss=6.34e-01\n",
      "Epoch 10, batch 251: \tunet loss=3.51e+00, \tcritic loss=6.59e-01\n",
      "Epoch 10, batch 261: \tunet loss=3.52e+00, \tcritic loss=6.65e-01\n",
      "Epoch 10, batch 271: \tunet loss=3.58e+00, \tcritic loss=6.73e-01\n",
      "Epoch 10, batch 281: \tunet loss=3.58e+00, \tcritic loss=6.47e-01\n",
      "Epoch 10, batch 291: \tunet loss=3.54e+00, \tcritic loss=6.97e-01\n",
      "Epoch 10, batch 301: \tunet loss=3.62e+00, \tcritic loss=7.26e-01\n",
      "Epoch 10, batch 311: \tunet loss=3.59e+00, \tcritic loss=7.29e-01\n",
      "Epoch 10, batch 321: \tunet loss=3.67e+00, \tcritic loss=7.30e-01\n",
      "Epoch 10, batch 331: \tunet loss=3.64e+00, \tcritic loss=6.71e-01\n",
      "Epoch 10, batch 341: \tunet loss=3.51e+00, \tcritic loss=6.66e-01\n",
      "Epoch 10, batch 351: \tunet loss=3.43e+00, \tcritic loss=6.55e-01\n",
      "Epoch 10, batch 361: \tunet loss=3.42e+00, \tcritic loss=7.10e-01\n",
      "Epoch 10, batch 371: \tunet loss=3.48e+00, \tcritic loss=7.32e-01\n",
      "Epoch 10, batch 381: \tunet loss=3.42e+00, \tcritic loss=7.13e-01\n",
      "Epoch 10, batch 391: \tunet loss=3.69e+00, \tcritic loss=6.69e-01\n",
      "Epoch 11, batch 10: \tunet loss=3.50e+00, \tcritic loss=6.67e-01\n",
      "Epoch 11, batch 20: \tunet loss=3.51e+00, \tcritic loss=7.32e-01\n",
      "Epoch 11, batch 30: \tunet loss=3.56e+00, \tcritic loss=6.95e-01\n",
      "Epoch 11, batch 40: \tunet loss=3.56e+00, \tcritic loss=6.91e-01\n",
      "Epoch 11, batch 50: \tunet loss=3.60e+00, \tcritic loss=7.05e-01\n",
      "Epoch 11, batch 60: \tunet loss=3.55e+00, \tcritic loss=6.94e-01\n",
      "Epoch 11, batch 70: \tunet loss=3.53e+00, \tcritic loss=6.35e-01\n",
      "Epoch 11, batch 80: \tunet loss=3.48e+00, \tcritic loss=6.49e-01\n",
      "Epoch 11, batch 90: \tunet loss=3.52e+00, \tcritic loss=7.11e-01\n",
      "saved parameters\n",
      "Epoch 11, batch 100: \tunet loss=3.45e+00, \tcritic loss=7.37e-01\n",
      "Epoch 11, batch 110: \tunet loss=3.45e+00, \tcritic loss=6.86e-01\n",
      "Epoch 11, batch 120: \tunet loss=3.58e+00, \tcritic loss=6.84e-01\n",
      "Epoch 11, batch 130: \tunet loss=3.49e+00, \tcritic loss=6.73e-01\n",
      "Epoch 11, batch 140: \tunet loss=3.59e+00, \tcritic loss=7.01e-01\n",
      "Epoch 11, batch 150: \tunet loss=3.63e+00, \tcritic loss=6.66e-01\n",
      "Epoch 11, batch 160: \tunet loss=3.51e+00, \tcritic loss=6.68e-01\n",
      "Epoch 11, batch 170: \tunet loss=3.49e+00, \tcritic loss=7.17e-01\n",
      "Epoch 11, batch 180: \tunet loss=3.62e+00, \tcritic loss=6.91e-01\n",
      "Epoch 11, batch 190: \tunet loss=3.49e+00, \tcritic loss=6.37e-01\n",
      "Epoch 11, batch 200: \tunet loss=3.65e+00, \tcritic loss=7.00e-01\n",
      "Epoch 11, batch 210: \tunet loss=3.39e+00, \tcritic loss=7.49e-01\n",
      "Epoch 11, batch 220: \tunet loss=3.50e+00, \tcritic loss=7.14e-01\n",
      "Epoch 11, batch 230: \tunet loss=3.52e+00, \tcritic loss=6.82e-01\n",
      "Epoch 11, batch 240: \tunet loss=3.56e+00, \tcritic loss=7.00e-01\n",
      "Epoch 11, batch 250: \tunet loss=3.51e+00, \tcritic loss=6.99e-01\n",
      "Epoch 11, batch 260: \tunet loss=3.40e+00, \tcritic loss=6.57e-01\n",
      "Epoch 11, batch 270: \tunet loss=3.67e+00, \tcritic loss=6.94e-01\n",
      "Epoch 11, batch 280: \tunet loss=3.55e+00, \tcritic loss=6.79e-01\n",
      "Epoch 11, batch 290: \tunet loss=3.42e+00, \tcritic loss=7.21e-01\n",
      "Epoch 11, batch 300: \tunet loss=3.59e+00, \tcritic loss=6.73e-01\n",
      "Epoch 11, batch 310: \tunet loss=3.49e+00, \tcritic loss=6.76e-01\n",
      "Epoch 11, batch 320: \tunet loss=3.53e+00, \tcritic loss=6.23e-01\n",
      "Epoch 11, batch 330: \tunet loss=3.48e+00, \tcritic loss=7.14e-01\n",
      "Epoch 11, batch 340: \tunet loss=3.45e+00, \tcritic loss=7.09e-01\n",
      "Epoch 11, batch 350: \tunet loss=3.61e+00, \tcritic loss=7.05e-01\n",
      "Epoch 11, batch 360: \tunet loss=3.59e+00, \tcritic loss=6.54e-01\n",
      "Epoch 11, batch 370: \tunet loss=3.52e+00, \tcritic loss=6.87e-01\n",
      "Epoch 11, batch 380: \tunet loss=3.40e+00, \tcritic loss=6.86e-01\n",
      "Epoch 11, batch 390: \tunet loss=3.50e+00, \tcritic loss=6.64e-01\n",
      "Epoch 12, batch 9: \tunet loss=3.21e+00, \tcritic loss=6.30e-01\n",
      "Epoch 12, batch 19: \tunet loss=3.47e+00, \tcritic loss=7.33e-01\n",
      "Epoch 12, batch 29: \tunet loss=3.53e+00, \tcritic loss=7.46e-01\n",
      "Epoch 12, batch 39: \tunet loss=3.71e+00, \tcritic loss=6.72e-01\n",
      "Epoch 12, batch 49: \tunet loss=3.56e+00, \tcritic loss=6.69e-01\n",
      "Epoch 12, batch 59: \tunet loss=3.47e+00, \tcritic loss=6.74e-01\n",
      "Epoch 12, batch 69: \tunet loss=3.49e+00, \tcritic loss=7.04e-01\n",
      "Epoch 12, batch 79: \tunet loss=3.47e+00, \tcritic loss=6.86e-01\n",
      "Epoch 12, batch 89: \tunet loss=3.64e+00, \tcritic loss=7.16e-01\n",
      "Epoch 12, batch 99: \tunet loss=3.55e+00, \tcritic loss=7.31e-01\n",
      "Epoch 12, batch 109: \tunet loss=3.38e+00, \tcritic loss=6.70e-01\n",
      "Epoch 12, batch 119: \tunet loss=3.48e+00, \tcritic loss=7.02e-01\n",
      "Epoch 12, batch 129: \tunet loss=3.37e+00, \tcritic loss=6.92e-01\n",
      "Epoch 12, batch 139: \tunet loss=3.37e+00, \tcritic loss=6.55e-01\n",
      "Epoch 12, batch 149: \tunet loss=3.50e+00, \tcritic loss=6.31e-01\n",
      "Epoch 12, batch 159: \tunet loss=3.42e+00, \tcritic loss=6.70e-01\n",
      "Epoch 12, batch 169: \tunet loss=3.57e+00, \tcritic loss=7.26e-01\n",
      "Epoch 12, batch 179: \tunet loss=3.48e+00, \tcritic loss=7.06e-01\n",
      "Epoch 12, batch 189: \tunet loss=3.49e+00, \tcritic loss=6.79e-01\n",
      "Epoch 12, batch 199: \tunet loss=3.51e+00, \tcritic loss=6.98e-01\n",
      "saved parameters\n",
      "Epoch 12, batch 209: \tunet loss=3.46e+00, \tcritic loss=7.13e-01\n",
      "Epoch 12, batch 219: \tunet loss=3.50e+00, \tcritic loss=7.02e-01\n",
      "Epoch 12, batch 229: \tunet loss=3.47e+00, \tcritic loss=6.31e-01\n",
      "Epoch 12, batch 239: \tunet loss=3.54e+00, \tcritic loss=6.23e-01\n",
      "Epoch 12, batch 249: \tunet loss=3.50e+00, \tcritic loss=6.34e-01\n",
      "Epoch 12, batch 259: \tunet loss=3.52e+00, \tcritic loss=7.24e-01\n",
      "Epoch 12, batch 269: \tunet loss=3.60e+00, \tcritic loss=6.91e-01\n",
      "Epoch 12, batch 279: \tunet loss=3.52e+00, \tcritic loss=6.63e-01\n",
      "Epoch 12, batch 289: \tunet loss=3.43e+00, \tcritic loss=6.87e-01\n",
      "Epoch 12, batch 299: \tunet loss=3.53e+00, \tcritic loss=7.14e-01\n",
      "Epoch 12, batch 309: \tunet loss=3.49e+00, \tcritic loss=7.08e-01\n",
      "Epoch 12, batch 319: \tunet loss=3.57e+00, \tcritic loss=6.93e-01\n",
      "Epoch 12, batch 329: \tunet loss=3.57e+00, \tcritic loss=6.49e-01\n",
      "Epoch 12, batch 339: \tunet loss=3.57e+00, \tcritic loss=6.98e-01\n",
      "Epoch 12, batch 349: \tunet loss=3.29e+00, \tcritic loss=7.15e-01\n",
      "Epoch 12, batch 359: \tunet loss=3.45e+00, \tcritic loss=6.93e-01\n",
      "Epoch 12, batch 369: \tunet loss=3.51e+00, \tcritic loss=6.58e-01\n",
      "Epoch 12, batch 379: \tunet loss=3.39e+00, \tcritic loss=6.45e-01\n",
      "Epoch 12, batch 389: \tunet loss=3.52e+00, \tcritic loss=7.01e-01\n",
      "Epoch 13, batch 8: \tunet loss=2.75e+00, \tcritic loss=6.02e-01\n",
      "Epoch 13, batch 18: \tunet loss=3.56e+00, \tcritic loss=6.58e-01\n",
      "Epoch 13, batch 28: \tunet loss=3.58e+00, \tcritic loss=6.52e-01\n",
      "Epoch 13, batch 38: \tunet loss=3.38e+00, \tcritic loss=7.14e-01\n",
      "Epoch 13, batch 48: \tunet loss=3.42e+00, \tcritic loss=6.78e-01\n",
      "Epoch 13, batch 58: \tunet loss=3.45e+00, \tcritic loss=6.50e-01\n",
      "Epoch 13, batch 68: \tunet loss=3.43e+00, \tcritic loss=7.42e-01\n",
      "Epoch 13, batch 78: \tunet loss=3.46e+00, \tcritic loss=6.92e-01\n",
      "Epoch 13, batch 88: \tunet loss=3.45e+00, \tcritic loss=6.55e-01\n",
      "Epoch 13, batch 98: \tunet loss=3.47e+00, \tcritic loss=6.43e-01\n",
      "Epoch 13, batch 108: \tunet loss=3.53e+00, \tcritic loss=6.70e-01\n",
      "Epoch 13, batch 118: \tunet loss=3.51e+00, \tcritic loss=6.51e-01\n",
      "Epoch 13, batch 128: \tunet loss=3.50e+00, \tcritic loss=7.40e-01\n",
      "Epoch 13, batch 138: \tunet loss=3.57e+00, \tcritic loss=7.60e-01\n",
      "Epoch 13, batch 148: \tunet loss=3.58e+00, \tcritic loss=7.42e-01\n",
      "Epoch 13, batch 158: \tunet loss=3.53e+00, \tcritic loss=6.58e-01\n",
      "Epoch 13, batch 168: \tunet loss=3.65e+00, \tcritic loss=7.17e-01\n",
      "Epoch 13, batch 178: \tunet loss=3.39e+00, \tcritic loss=6.47e-01\n",
      "Epoch 13, batch 188: \tunet loss=3.46e+00, \tcritic loss=6.12e-01\n",
      "Epoch 13, batch 198: \tunet loss=3.58e+00, \tcritic loss=6.96e-01\n",
      "Epoch 13, batch 208: \tunet loss=3.44e+00, \tcritic loss=6.94e-01\n",
      "Epoch 13, batch 218: \tunet loss=3.60e+00, \tcritic loss=7.04e-01\n",
      "Epoch 13, batch 228: \tunet loss=3.50e+00, \tcritic loss=7.08e-01\n",
      "Epoch 13, batch 238: \tunet loss=3.50e+00, \tcritic loss=6.58e-01\n",
      "Epoch 13, batch 248: \tunet loss=3.57e+00, \tcritic loss=6.89e-01\n",
      "Epoch 13, batch 258: \tunet loss=3.53e+00, \tcritic loss=6.84e-01\n",
      "Epoch 13, batch 268: \tunet loss=3.43e+00, \tcritic loss=6.27e-01\n",
      "Epoch 13, batch 278: \tunet loss=3.43e+00, \tcritic loss=6.90e-01\n",
      "Epoch 13, batch 288: \tunet loss=3.51e+00, \tcritic loss=7.47e-01\n",
      "Epoch 13, batch 298: \tunet loss=3.65e+00, \tcritic loss=7.11e-01\n",
      "Epoch 13, batch 308: \tunet loss=3.57e+00, \tcritic loss=6.48e-01\n",
      "saved parameters\n",
      "Epoch 13, batch 318: \tunet loss=3.50e+00, \tcritic loss=6.65e-01\n",
      "Epoch 13, batch 328: \tunet loss=3.48e+00, \tcritic loss=6.70e-01\n",
      "Epoch 13, batch 338: \tunet loss=3.42e+00, \tcritic loss=6.74e-01\n",
      "Epoch 13, batch 348: \tunet loss=3.59e+00, \tcritic loss=6.96e-01\n",
      "Epoch 13, batch 358: \tunet loss=3.64e+00, \tcritic loss=6.68e-01\n",
      "Epoch 13, batch 368: \tunet loss=3.40e+00, \tcritic loss=6.61e-01\n",
      "Epoch 13, batch 378: \tunet loss=3.46e+00, \tcritic loss=6.83e-01\n",
      "Epoch 13, batch 388: \tunet loss=3.61e+00, \tcritic loss=6.78e-01\n",
      "Epoch 14, batch 7: \tunet loss=2.44e+00, \tcritic loss=4.61e-01\n",
      "Epoch 14, batch 17: \tunet loss=3.55e+00, \tcritic loss=6.57e-01\n",
      "Epoch 14, batch 27: \tunet loss=3.49e+00, \tcritic loss=7.09e-01\n",
      "Epoch 14, batch 37: \tunet loss=3.55e+00, \tcritic loss=6.76e-01\n",
      "Epoch 14, batch 47: \tunet loss=3.54e+00, \tcritic loss=6.50e-01\n",
      "Epoch 14, batch 57: \tunet loss=3.48e+00, \tcritic loss=6.99e-01\n",
      "Epoch 14, batch 67: \tunet loss=3.56e+00, \tcritic loss=6.80e-01\n",
      "Epoch 14, batch 77: \tunet loss=3.62e+00, \tcritic loss=6.99e-01\n",
      "Epoch 14, batch 87: \tunet loss=3.52e+00, \tcritic loss=6.73e-01\n",
      "Epoch 14, batch 97: \tunet loss=3.52e+00, \tcritic loss=7.28e-01\n",
      "Epoch 14, batch 107: \tunet loss=3.45e+00, \tcritic loss=7.58e-01\n",
      "Epoch 14, batch 117: \tunet loss=3.61e+00, \tcritic loss=7.00e-01\n",
      "Traceback (most recent call last):\n",
      "  File \"train_gan.py\", line 277, in <module>\n",
      "    main(sys.argv[1:])\n",
      "  File \"train_gan.py\", line 228, in main\n",
      "    real_loss=criterion(crit(image)[:,0],ones[:batch_size])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\", line 512, in forward\n",
      "    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 2113, in binary_cross_entropy\n",
      "    input, target, weight, reduction_enum)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "#jenachdem wo dein AML ordner ist in der drive musst du den Pfad anpassen (-w %PATH%)\n",
    "#falls mit neuen hyperparametern trainiert werden soll sollte man -n ändern\n",
    "!python train_gan.py -b 128 -m u -n unet_cifar -w \"/content/drive/My Drive/Uni/6. Semester/Advanced Machine Learning/project/weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1561465779328,
     "user": {
      "displayName": "Lukas Blecher",
      "photoUrl": "https://lh4.googleusercontent.com/-XtV6iVD9kww/AAAAAAAAAAI/AAAAAAAABoY/2RsKKwD6uh0/s64/photo.jpg",
      "userId": "14271751097560078622"
     },
     "user_tz": -120
    },
    "id": "2E7aDtqdb5bN",
    "outputId": "22bf25b0-aeee-405c-a009-7fc4657a4df1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OVCDv5E5idd"
   },
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naibtGDd5iHW"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "#löscht den ordner\n",
    "shutil.rmtree('AML_Colorization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCC8UPtcnJlt"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1565025754297,
     "user": {
      "displayName": "Lukas Blecher",
      "photoUrl": "https://lh4.googleusercontent.com/-XtV6iVD9kww/AAAAAAAAAAI/AAAAAAAABoY/2RsKKwD6uh0/s64/photo.jpg",
      "userId": "14271751097560078622"
     },
     "user_tz": -120
    },
    "id": "P5N34yDv7APQ",
    "outputId": "601db22f-42ac-4cfe-855f-9270b2fc855a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects:  14% (1/7)   \u001b[K\r",
      "remote: Counting objects:  28% (2/7)   \u001b[K\r",
      "remote: Counting objects:  42% (3/7)   \u001b[K\r",
      "remote: Counting objects:  57% (4/7)   \u001b[K\r",
      "remote: Counting objects:  71% (5/7)   \u001b[K\r",
      "remote: Counting objects:  85% (6/7)   \u001b[K\r",
      "remote: Counting objects: 100% (7/7)   \u001b[K\r",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects:  25% (1/4)   \u001b[K\r",
      "remote: Compressing objects:  50% (2/4)   \u001b[K\r",
      "remote: Compressing objects:  75% (3/4)   \u001b[K\r",
      "remote: Compressing objects: 100% (4/4)   \u001b[K\r",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 6 (delta 3), reused 5 (delta 2), pack-reused 0\u001b[K\n",
      "Unpacking objects:  16% (1/6)   \r",
      "Unpacking objects:  33% (2/6)   \r",
      "Unpacking objects:  50% (3/6)   \r",
      "Unpacking objects:  66% (4/6)   \r",
      "Unpacking objects:  83% (5/6)   \r",
      "Unpacking objects: 100% (6/6)   \r",
      "Unpacking objects: 100% (6/6), done.\n",
      "From https://github.com/ml4cdeca/AML_Colorization\n",
      "   4f00d48..a9ea125  master     -> origin/master\n",
      "Updating 4f00d48..a9ea125\n",
      "Fast-forward\n",
      " train_unet.py | 219 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
      " 1 file changed, 219 insertions(+)\n",
      " create mode 100644 train_unet.py\n"
     ]
    }
   ],
   "source": [
    "#pullt\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzyCjRJa68oB"
   },
   "source": [
    "how much gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14835,
     "status": "ok",
     "timestamp": 1561565568472,
     "user": {
      "displayName": "Lukas Blecher",
      "photoUrl": "https://lh4.googleusercontent.com/-XtV6iVD9kww/AAAAAAAAAAI/AAAAAAAABoY/2RsKKwD6uh0/s64/photo.jpg",
      "userId": "14271751097560078622"
     },
     "user_tz": -120
    },
    "id": "Cloal__069lB",
    "outputId": "6214c5e6-47b5-40e6-b72f-e555a6537815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "Building wheels for collected packages: gputil\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.4.0\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
      "Gen RAM Free: 12.8 GB  | Proc size: 151.0 MB\n",
      "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
     ]
    }
   ],
   "source": [
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ae8hz5y1VM5u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "colorization.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
